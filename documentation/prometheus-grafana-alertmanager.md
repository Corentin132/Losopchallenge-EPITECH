# Configuration de Prometheus, Grafana et AlertManager

## Composants

NameSpace : "monitoring"  
`kubectl apply -f prometheus-ns.yml`  
ğŸ“‘ Isoler les ressources de Prometheus (pods, services, grafana, alertmanager...) dans leur propre espace logique au sein du cluster

## node-exporter

**Agent qui collecte des mÃ©triques hardware et OS des nodes du cluster Kubernetes**

1. node-exporter daemonset  
   `kubectl apply -f node-exporter-daemonset.yml`  
   ğŸ‹ Image -> prom/node-exporter:v1.7.0  
   ğŸ“‘ Collecter des mÃ©triques sur l'Ã©tat des nodes  
   \- Disponible sur <node_ip>:9100  
   \- Node Exporter sur chaque node du cluster  
   \- Config : Node Exporter dÃ©ployÃ© sur chaque node du cluster. Utilise le rÃ©seau et les PID de l'hÃ´te pour une collecter les mÃ©triques

   ![NodeExporter-Metrics](./images/node-exporter.png)

2. node-exporter service  
   `kubectl apply -f node-exporter-service.yml`  
   ğŸ“‘ Rendre Node Exporter uniquement accessible Ã  travers le cluster  
   \- ClusterIP : permet l'accÃ¨s interne au service Node Exporter, sans exposition directe Ã  l'extÃ©rieur du cluster

## kube-state-metrics

**Application servant d'interface entre l'API Kubernetes et Prometheus. Elle scrute l'Ã©tat des objets Kube et gÃ©nÃ¨re les mÃ©triques de l'Ã©tat interne du cluster**

1. ServiceAccount  
   `kubectl apply -f kube-state-metrics-ServiceAccount.yml`  
   ğŸ“‘ Assure une authentification et une autorisation pour accÃ©der aux ressources de l'API Kubernetes  
   \- ClusterRole -> RÃ¨gles de permissions : AccÃ¨s en lecture sur des ressources  
   \- ClusterRoleBinding -> Associer le ServiceAccount de kube-state-metrics au ClusterRole pour utiliser les permissions au niveau de tout le cluster  
   \- RBAC (Role-Based Access Control) sÃ©curise l'accÃ¨s aux informations sans droits excessifs sur le cluster

2. kube-state-metrics deployment  
   `kubectl apply -f kube-state-metrics-deployment.yml`  
   ğŸ‹ Image -> bitnami/kube-state-metrics  
   ğŸ“‘ DÃ©ploie le service d'Ã©coute de l'API Kube et gÃ©nÃ¨re des mÃ©trics sur l'Ã©tat des objets (pods, dÃ©ploiements...)

3. kube-state-metrics service  
   `kubectl apply -f kube-state-metrics-service.yml`  
   ğŸ“‘ Rendre le service kube-state-metrics accessible Ã  l'intÃ©rieur du cluster pour que Prometheus puisse rÃ©cupÃ©rer les mÃ©triques de Kubernetes
   \- Le service est de type ClusterIP par dÃ©faut

   ![Kube-state-metrics](./images/kube-state-metrics.png)

## Prometheus

**SystÃ¨me de monitoring et d'alerte qui collecte les mÃ©triques depuis des targets configurÃ©es Ã  intervalles de temps**

1. ServiceAccount  
   `kubectl apply -f prometheus-k8s-ServiceAccount.yml`  
   ğŸ“‘ Ppermet Ã  Prometheus d'interagir avec l'API Kubernetes  
   \- ClusterRole : RÃ¨gles d'accÃ¨s aux ressources pour que Prometheus puisse effectuer ses tÃ¢ches de monitoring et d'alerte -> AccÃ¨s en lecture (nodes, nodes/proxy, services, endpoints, pods) et accÃ¨s en lecture ("get") sur les configmaps. AccÃ¨s aux requÃªtes GET sur les URLs <ressources>/metrics  
   \- ClusterRoleBinding - Associe le ServiceAccount prometheus-k8s au ClusterRole prometheus pouyr qu'il dispose des droits d'accÃ¨s Ã  tout le cluster  
   \- RBAC

2. Configmap config  
   `kubectl apply -f prometheus-config-configmap.yml`  
   ğŸ“‘ Configuration des targets, des rules...  
   ğŸŒ [sources](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#kubernetes_sd_config)

3. Configmap rules  
   `kubectl apply -f prometheus-rules-configmap.yml`  
   ğŸ“‘ Configuration des rÃ¨gles d'alerte  
   ğŸ“‘ [Voir les rÃ¨gles d'alertes](#alertes)

4. Les secret de Prometheus  
   `kubectl apply -f prometheus-secret.yml`  
   ğŸ“‘ Contient les secrets utilisÃ©s par Prometheus

5. DÃ©ploiement du serveur Prometheus  
   `kubectl apply -f prometheus-deployment.yml`  
   ğŸ‹ Image -> prom/prometheus:v2.50.0  
   ğŸ“‘ DÃ©ploie Prometheus dans le cluster. DÃ©finit le nombre de rÃ©pliques, les images, les volumes...

6. Service du serveur Prometheus  
   `kubectl apply -f prometheus-service.yml`  
   \- ClusterIP : accessible uniquement de l'intÃ©rieur du cluster

   ![Prometheus-ui](./images/prometheus-ui.png)

## Grafana

**Outil de visualisation de donnÃ©es de monitoring Ã  travers des dashboards**

1. Grafana Dashboard configmap  
   `kubectl apply -f grafana-dashboard-configmap.yml`  
   ğŸŒ [sources](https://grafana.com/grafana/dashboards)

2. Grafana datasources configmap  
   `kubectl apply -f grafana-datasources-configmap.yml`

3. Grafana provider configmap  
   `kubectl apply -f grafana-provider-configmap.yml`

4. Grafana PersistentVolumeClaim
   `kubectl apply -f grafana-persistent-storage.yml`

5. DÃ©ploiement du serveur Grafana  
   `kubectl apply -f grafana-deployment.yml`  
   ğŸ‹ Image -> grafana/grafana:10.1.9

6. Service Grafana Server  
   `kubectl apply -f grafana-service.yml`
   \- NodePort : accessible depuis l'extÃ©rieur du cluster via <Node_IP>:<Node_Port>

7. Mise en place de l'Ingress pour le service Grafana  
   `kubectl apply -f grafana-ingress.yml`  
   ğŸ“‘ Exposer Grafana hors du cluster via un nom de domaine <Host_Name>:<Node_Port> Grafana  
   \- Port : 3000 -> NodePort pour accÃ¨s externe  
   \- DNS/Hosts : Modifier /etc/hosts ou configurer DNS pour rÃ©soudre le nom de domaine vers l'IP du node Ingress

   ![grafana](./images/grafana.png)

## Alertmanager

**Le gestionnaire d'alertes gÃ¨re les alertes envoyÃ©es par des applications clientes comme Prometheus, en les regroupant et en les routant vers un webhook Discord**

1. Persistent Volume Claim  
   `kubectl apply -f alertmanager-pvc.yml`  
   ğŸ“‘ Stock les donnÃ©es d'alerte, de config et de logs Ã  travers les redÃ©marrages du pod ou du service  
   \- ReadWriteOnce : Le volume peut Ãªtre montÃ© en lecture/Ã©criture sur un seul node

2. Les secret de Prometheus  
   `kubectl apply -f alertmanager-secret.yml`  
   ğŸ“‘ Contient l'URL_DISCORD

3. Alertmanager Configmap config  
   `kubectl apply -f alertmanager-config-configmap.yml`  
   ğŸ“‘ Configuration des destinations d'alertes sur Discord  
   ğŸŒ [sources](https://prometheus.io/docs/alerting/configuration/)

4. Alertmanager Configmap template  
   `kubectl apply -f alertmanager-templates-configmap.yml`

5. DÃ©ploiement d'Alertmanager  
   `kubectl apply -f alertmanager-deployment.yml`  
   ğŸ‹ Image Docker de rogerrum/alertmanager-discord:1.0.5  
   \- Webhook : envoyer des alertes en utilisant des requÃªtes HTTP POST

6. Service Alertmanager  
   `kubectl apply -f alertmanager-service.yml`  
   \- NodePort, Alertmanager accessible depuis l'extÃ©rieur du cluster
   \- AccÃ©der Ã  Alertmanager adresse IP d'un des nnode + port allouÃ© par Kubernetes <Node_IP>:<Node_Port>
   \- exposer sur /metrics, les mÃ©triques de l'alertmanager lui mÃªme
   \- Port : configurÃ© pour Ã©couter sur le port 9093, utilisÃ© par Alertmanager pour son interface web et son API

   ![alerte-discord](./images/alerte-discord.png)

## Alertes

**RÃ¨gles de dÃ©clenchement des alertes**  
dans prometheus-rules-configmap.yml

1. Utilisation Ã‰levÃ©e du CPU  
   ğŸš¨ "HighCpuUsage"  
   Alerte dÃ©clenchÃ©e si l'utilisation moyenne du CPU par instance dÃ©passe 40% pendant plus d'une minute
2. Utilisation Ã‰levÃ©e de la MÃ©moire  
   ğŸš¨ "HighMemoryUsage"  
   Alerte activÃ©e lorsque la mÃ©moire utilisÃ©e dÃ©passe 50% de la mÃ©moire totale disponible par instance pendant plus d'une minute
3. DÃ©faillance des Pods  
   ğŸš¨ "HighPodFailure"  
   Alerte dÃ©clenchÃ©e si plus de 5 pods sont dans un Ã©tat d'Ã©chec pendant plus d'une minute

## RÃ©cupÃ©rer l'ensemble des composants du namespace

`kubectl get all -n monitoring`
